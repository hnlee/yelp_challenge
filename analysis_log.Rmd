Analysis log
========================================================

### 2015.10.13

* Installed `jsonlite` and `knitr` packages

```{r}
setwd('/Users/hanalee/yelp_challenge')
library(jsonlite)
```

### 2015.10.17

Load data and cache for loading
```{r}
business <- stream_in(file("dataset/yelp_academic_dataset_business.json"))
checkin <- stream_in(file("dataset/yelp_academic_dataset_checkin.json"))
review <- stream_in(file("dataset/yelp_academic_dataset_review.json"))
tip <- stream_in(file("dataset/yelp_academic_dataset_tip.json"))
user <- stream_in(file("dataset/yelp_academic_dataset_user.json"))
yelp_data <- save(business, checkin, review, tip, user,
                  file="yelp_data.rda")
```

Exploratory data analysis for quiz 1
```{r}
nrow(review)
review[100,]
colnames(review)
length(which(review$stars==5))/nrow(review)

nrow(business)
colnames(business)
colnames(business$attributes)
length(which(business$attributes[,"Wi-Fi"] == "free"))/sum(!(is.na(business$attributes[,"Wi-Fi"])))

nrow(tip)
tip[1000,]

colnames(user)
colnames(user$votes)
intersect(c("Ira","Brian","Jeff","Roger"), user[which(user$votes[,"funny"] > 10000), "name"])
fisher.test(table(user$votes[,"funny"] > 1, user$fans > 1))
```

### 2015.10.23

```{r}
load("yelp_data.rda")
library(dplyr)
library(reshape2)
library(caret)
```

I'm interested in urban planning aspects of the data set. Possible  questions for the project:
* Predict food deserts
* Predict neighborhood popularity (with locals, with tourists)
* Predict neighborhood of a business given the users who review it
* Predict priciness of a neighborhood

Pre-processing steps
* I want to create a variable to code for which metropolitan area
  * Must determine which latitude & longitude ranges are appropriate
  * Use a function to detect clusters
  * Ten cities so k-means where k=10
* Within each city, identify neighborhoods
  * Do neighborhoods overlap?
  * Infer missing values for businesses without neighborhood based on latitude and longitude
* Do I need to be more local than neighborhood?

```{r}
cities <- kmeans(select(business, latitude, longitude), 
                 centers=10, nstart=10000, iter.max=10000)
cities$size
cities$centers
length(cities$cluster)
business$metro <- as.factor(cities$cluster)

cityplot <- ggplot(data=select(business, metro, latitude, longitude)) 
cityplot + geom_point(aes(x=longitude, y=latitude, color=metro))
```

Partitioning steps
* 10% of business_id for test set?

```{r}
length(setdiff(checkin$business_id, business$business_id))
length(setdiff(tip$business_id, business$business_id))
length(setdiff(review$business_id, business$business_id))
```

### 2015.10.25

Need to avoid circularity where what is being predicted is also in the predictors.

Use external data set to determine what to predict?

Predict something about a category of businesses?

Cities can be assigned based on states rather than through k-means

```{r}
levels(as.factor(business$state))
sapply(levels(as.factor(business$state)), function(x) {
  nrow(business[business$state == x,])
})
business$metro <- sapply(business$city, function(x){
  if(x == "AZ"){return("Phoenix")}
  if(x == "IL"){return("Urbana-Champaign")}
  if(x %in% c("NC", "SC")){return("Charlotte")}
  if(x == "NV"){return("Las Vegas")}
  if(x == "PA"){return("Pittsburgh")}
  if(x == "WI"){return("Madison")}
  if(x == "QC"){return("Montreal")}
  if(x == "ON"){return("Waterloo")}
  if(x %in% c("BW", "RP")){return("Karlsruhe")}
  if(x %in% c("EDH", "ELN", "FIF", "HAM", "KHL", "MLN", "NTH", "SCB", "XGL")){
    return("Edinburgh")
  } else { return(NA)}
})
```